{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480ab0e-c04a-4618-aebd-66bdec15e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# 全局变量\n",
    "max_length = 10\n",
    "pad_item = 2359\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def pad_history(itemlist, length, pad_item):\n",
    "    if len(itemlist) >= length:\n",
    "        return itemlist[-length:]\n",
    "    else:\n",
    "        return itemlist + [pad_item] * (length - len(itemlist))\n",
    "\n",
    "def generate_sequences(data, is_train=True, max_length=10, pad_item=2359):\n",
    "    sequences = []\n",
    "    for user_id, books in data.items():\n",
    "        if is_train:\n",
    "            # 训练集：为每次交互生成一个序列\n",
    "            history = []\n",
    "            for book in books:\n",
    "                s = list(history)\n",
    "                if s:  # 只有当历史不为空时才生成序列\n",
    "                    len_s = len(s) if len(s) < max_length else max_length\n",
    "                    s = pad_history(s, max_length, pad_item)\n",
    "                    \n",
    "                    # 过滤掉全是填充值的序列\n",
    "                    if not all(item == pad_item for item in s):\n",
    "                        sequences.append({\n",
    "                            'seq': s,\n",
    "                            'len_seq': len_s,\n",
    "                            'next': book['book_id']\n",
    "                        })\n",
    "                \n",
    "                history.append(book['book_id'])\n",
    "                if len(history) > max_length:\n",
    "                    history = history[-max_length:]\n",
    "        else:\n",
    "            # 验证集/测试集：每个用户只生成一个序列\n",
    "            history = [book['book_id'] for book in books[:-1]]\n",
    "            if history:  # 只有当历史不为空时才生成序列\n",
    "                s = pad_history(history, max_length, pad_item)\n",
    "                len_s = len(history) if len(history) < max_length else max_length\n",
    "                \n",
    "                # 过滤掉全是填充值的序列\n",
    "                if not all(item == pad_item for item in s):\n",
    "                    sequences.append({\n",
    "                        'seq': s,\n",
    "                        'len_seq': len_s,\n",
    "                        'next': books[-1]['book_id']\n",
    "                    })\n",
    "    \n",
    "    df = pd.DataFrame(sequences)\n",
    "    df.reset_index(drop=True, inplace=True)  # 确保索引从0开始\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_data_by_time(data, time_field='read_at'):\n",
    "    id_time = defaultdict(list)\n",
    "    for user_id, books in data.items():\n",
    "        if books:\n",
    "            earliest_time = min(book.get(time_field, 0) for book in books)\n",
    "            id_time[user_id] = earliest_time\n",
    "    \n",
    "    sorted_ids = sorted(id_time, key=id_time.get)\n",
    "    \n",
    "    total_users = len(sorted_ids)\n",
    "    train_size = int(0.8 * total_users)\n",
    "    val_size = int(0.1 * total_users)\n",
    "    \n",
    "    train_ids = sorted_ids[:train_size]\n",
    "    val_ids = sorted_ids[train_size:train_size+val_size]\n",
    "    test_ids = sorted_ids[train_size+val_size:]\n",
    "    \n",
    "    return train_ids, val_ids, test_ids\n",
    "\n",
    "def print_dataset_info(name, df):\n",
    "    print(f\"\\n{name} 信息:\")\n",
    "    print(f\"  总序列数: {len(df)}\")\n",
    "    print(f\"  len_seq 分布:\\n{df['len_seq'].value_counts().sort_index()}\")\n",
    "    print(\"\\n  前5行数据:\")\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    print(df.head().to_string())\n",
    "    print(\"\\n  seq列的前5个元素:\")\n",
    "    for i, seq in enumerate(df['seq'].head(), 1):\n",
    "        print(f\"    序列 {i}: {seq}\")\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/workspace/Goodreads/history/remapped_ya_user_sessions.json'\n",
    "    data = load_data(file_path)\n",
    "\n",
    "    # 检查数据结构\n",
    "    sample_user = next(iter(data))\n",
    "    sample_book = data[sample_user][0]\n",
    "    print(\"Sample book data:\", sample_book)\n",
    "\n",
    "    # 确定时间字段\n",
    "    time_field = 'read_at'  # 根据实际数据结构调整这个字段名\n",
    "    if time_field not in sample_book:\n",
    "        print(f\"Warning: '{time_field}' not found in the data. Please specify the correct time field.\")\n",
    "        time_field = input(\"Please enter the correct time field name: \")\n",
    "\n",
    "    # 按时间顺序划分数据\n",
    "    train_ids, val_ids, test_ids = split_data_by_time(data, time_field)\n",
    "\n",
    "    train_data = {user: data[user] for user in train_ids}\n",
    "    val_data = {user: data[user] for user in val_ids}\n",
    "    test_data = {user: data[user] for user in test_ids}\n",
    "\n",
    "    # 生成序列\n",
    "    train_df = generate_sequences(train_data, is_train=True, max_length=max_length, pad_item=pad_item)\n",
    "    val_df = generate_sequences(val_data, is_train=False, max_length=max_length, pad_item=pad_item)\n",
    "    test_df = generate_sequences(test_data, is_train=False, max_length=max_length, pad_item=pad_item)\n",
    "\n",
    "    # 保存数据\n",
    "    train_df.to_pickle('/workspace/Goodreads/history/train_data.df')\n",
    "    val_df.to_pickle('/workspace/Goodreads/history/val_data.df')\n",
    "    test_df.to_pickle('/workspace/Goodreads/history/test_data.df')\n",
    "\n",
    "    # 生成 Test_data.df（与测试集相同，因为每个用户已经只有一个序列）\n",
    "    test_df.to_pickle('/workspace/Goodreads/history/Test_data.df')\n",
    "\n",
    "    # 打印数据集信息\n",
    "    print_dataset_info(\"训练集\", train_df)\n",
    "    print_dataset_info(\"验证集\", val_df)\n",
    "    print_dataset_info(\"测试集\", test_df)\n",
    "\n",
    "    # 额外的数据统计\n",
    "    print(\"\\n数据统计:\")\n",
    "    print(f\"总用户数: {len(data)}\")\n",
    "    print(f\"训练集用户数: {len(train_data)}\")\n",
    "    print(f\"验证集用户数: {len(val_data)}\")\n",
    "    print(f\"测试集用户数: {len(test_data)}\")\n",
    "    \n",
    "    all_book_ids = set()\n",
    "    for user_books in data.values():\n",
    "        all_book_ids.update(book['book_id'] for book in user_books)\n",
    "    print(f\"总图书数: {len(all_book_ids)}\")\n",
    "\n",
    "    print(\"\\n数据集生成并保存完成。\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
